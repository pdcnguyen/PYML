{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you start working on the exercise\n",
    "\n",
    "- Use Python version 3.9 and above.\n",
    "- It is highly recommended to create a virtual environment for this course. You can find resources on how to create a virtual environment on the ISIS page of the course.\n",
    "- Make sure that no assertions fail or exceptions occur, otherwise points will be subtracted.\n",
    "- Use all the variables given to a function unless explicitly stated otherwise. If you are not using a variable you are doing something wrong.\n",
    "- Read the **whole** task description before starting with your solution.\n",
    "- After you submit the notebook more tests will be run on your code. The fact that no assertions fail on your computer locally does not guarantee that you completed the exercise correctly.\n",
    "- Please submit only the notebook file with its original name. If you do not submit an `ipynb` file you will fail the exercise.\n",
    "- Edit only between YOUR CODE HERE and END YOUR CODE.\n",
    "- Verify that no syntax errors are present in the file.\n",
    "- Before uploading your submission, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel\\Restart) and then run all cells (in the menubar, select Cell\\Run All)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Python version\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if (3, 9) <= sys.version_info[:2] <= (3, 11):\n",
    "    print(\"Correct Python version\")\n",
    "else:\n",
    "    print(\n",
    "        f\"You are using a wrong version of Python: {'.'.join(map(str,sys.version_info[:3]))}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "377a4263c4e5fee5afe86fed54af5a8d",
     "grade": true,
     "grade_id": "cell-e5951c7ec892701b",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it\n",
    "\n",
    "# Use unittest asserts \n",
    "import unittest\n",
    "\n",
    "t = unittest.TestCase()\n",
    "from pprint import pprint\n",
    "\n",
    "# Helper assert function\n",
    "def assert_percentage(val):\n",
    "    t.assertGreaterEqual(val, 0.0, f\"Percentage ({val}) cannot be < 0\")\n",
    "    t.assertLessEqual(val, 1.0, f\"Percentage ({val}) cannot be > 1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20289a35a26a4e4743f4a3b57c562f26",
     "grade": false,
     "grade_id": "cell-dcb35deb0f0fe3e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Warm Ups\n",
    "\n",
    "Before starting the homework sheet we recommend you finish these warm-up tasks. They won't bring any points but should help you to get familiar with Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9a3bcc31f73bcf8a8942c6501930dfb",
     "grade": false,
     "grade_id": "cell-da302d4d2aa81a38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Function and types (0 P)\n",
    "\n",
    "Write a function using list comprehension that returns the types of list elements.\n",
    "\n",
    "* The function should be called `types_of`\n",
    "* The function expects a list as an input argument.\n",
    "* The function should return a list with the types of the given list elements.\n",
    "* Read the testing cell to understand how `types_of` is supposed to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f1a2833a501dc6e6d87342437ad04ac",
     "grade": false,
     "grade_id": "cell-8d004130189cffa5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def types_of(X : list):\n",
    "    return [type(x) for x in X]\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1da781e28dbf335a6b16e2da166ddac",
     "grade": true,
     "grade_id": "cell-e082a23baca66faf",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test type_of_two function\n",
    "types = types_of([7, 0.7, \"hello\", True, (2, \"s\")])\n",
    "\n",
    "assert isinstance(types, list)\n",
    "t.assertEqual(types[0], int)\n",
    "t.assertEqual(types[1], float)\n",
    "t.assertEqual(types[2], str)\n",
    "t.assertEqual(types[3], bool)\n",
    "t.assertEqual(types[-1], tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7cff5f72ed4ab8b4997d33ba714e7309",
     "grade": false,
     "grade_id": "cell-a1cca31a8ad0bffa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Concatenation and enumerate (0 P)\n",
    "\n",
    "\n",
    "Concatenate the strings from the array 'animals' into one string.\n",
    "\n",
    "* Use: `counting +=` and string formatting (`f-strings`).\n",
    "* Use `enumerate` to get the `i`th index.\n",
    "* The result should look as follows: `'0: mouse | 1: rabbit | 2: cat | 3: dog |'`\n",
    "\n",
    "***Note that this is not the most efficient way to concatenate strings in Python but part of this exercise is to showcase `for-loops`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ddfc76de1665ae61767d57a96b383d7",
     "grade": false,
     "grade_id": "cell-0107276bf8cc8cb9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "animals = [\"mouse\", \"rabbit\", \"cat\", \"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dced0f876b990f9400fe5ac575e74c67",
     "grade": false,
     "grade_id": "cell-598f867f4109ac39",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|0: mouse |1: rabbit |2: cat |3: dog |\n"
     ]
    }
   ],
   "source": [
    "counting = \"|\"\n",
    "for i, animal in enumerate(animals):\n",
    "    # YOUR CODE HERE\n",
    "    counting += f'{i}: {animal} |'\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "\n",
    "print(counting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "550c7835fbb04f9ca08ebc5181a6f218",
     "grade": true,
     "grade_id": "cell-cbf9e2c30017f8d7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test of the enumeration loop\n",
    "t.assertEqual(counting, \"|0: mouse |1: rabbit |2: cat |3: dog |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b99f341ff5892f09f3aa53bd2b4aba0",
     "grade": false,
     "grade_id": "cell-bc949de5bca7962f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### String formating (0 P)\n",
    "\n",
    "What does the following string formating result in?\n",
    "* Write the result of the string formating into the variables result1, result2, result3.\n",
    "* Example: `string0 = \"This is a {} string.\".format(\"test\")`\n",
    "* Example solution: `result0 = \"This is a test string\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36fdcaad313c8bcb3b68acf78377422d",
     "grade": false,
     "grade_id": "cell-38b920b1680007a2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# first string\n",
    "string1 = \"The sky is {}. {} words in front of {} random words create {} random sentence.\".format(\n",
    "    \"clear\", \"Random\", \"other\", 1\n",
    ")\n",
    "\n",
    "# second string\n",
    "a = \"irony\"\n",
    "b = \"anyone\"\n",
    "c = \"room\"\n",
    "\n",
    "string2 = f\"The {a} of the situation wasn't lost on {b} in the {c}.\"\n",
    "\n",
    "# third string\n",
    "string3 = f\"{7*10} * {9/3} with three digits after the floating point looks like this: {70*3 :.3f}.\"\n",
    "\n",
    "# fourth string\n",
    "string4 = \"   Hello World.   \".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6112db553e65d7266af4c18ca315f4e1",
     "grade": false,
     "grade_id": "cell-ab79852811b12118",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "result1 = 'The sky is clear. Random words in front of other random words create 1 random sentence.'\n",
    "result2 = 'The irony of the situation wasn\\'t lost on anyone in the room.'\n",
    "result3 = '70 * 3.0 with three digits after the floating point looks like this: 210.000.'\n",
    "result4 = 'Hello World.'\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efe22b83f2412859c1b3487955b525ab",
     "grade": true,
     "grade_id": "cell-09a4a5a04b6d9098",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test the string results\n",
    "t.assertEqual(string1, result1)\n",
    "t.assertEqual(string2, result2)\n",
    "t.assertEqual(string3, result3)\n",
    "t.assertEqual(string4, result4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb1331a0a4f56c92ea3d9271ea23e654",
     "grade": false,
     "grade_id": "cell-b2b789b02a0b4bf0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise Sheet 1: Python Basics\n",
    "\n",
    "This first  exercise sheet tests the basic functionalities of the Python programming language in the context of a simple prediction task. We consider the problem of predicting health risk of subjects from personal data and habits. We first use for this task a decision tree.\n",
    "\n",
    "![](tree.png)\n",
    "\n",
    "Make sure that you have downloaded the `tree.png` file from ISIS. For this exercise sheet, you are required to use only pure Python, and to not import any module, including `Numpy`. Next week are going to implement the nearest neighbor part of this exercise sheet using `NumPy` ðŸ˜‰."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f564e12d46d132b419ae75e9a1b1f46",
     "grade": false,
     "grade_id": "cell-33557bd5b8af8865",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Classifying a single instance (15 P)\n",
    "\n",
    "* In this sheet we will represent patient info as a tuple.\n",
    "* Implement the function `decision` that takes as input a tuple containing values for attributes (smoker,age,diet), and computes the output of the decision tree. Should return either `'less'` or `'more'`. No other outputs are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e86841c34c7d4bb4a2877c003b7c964",
     "grade": false,
     "grade_id": "cell-b66d7278bc313c94",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def decision(x):\n",
    "    \"\"\"\n",
    "    This function implements the decision tree represented in the above image. As input the function\n",
    "    receives a tuple with three values that represent some information about a patient.\n",
    "    Args:\n",
    "        x: Input tuple containing exactly three values.\n",
    "        The first element represents a patient is a smoker this value will be 'yes'.\n",
    "        All other values represent that the patient is not a smoker. The second\n",
    "        element represents the age of a patient in years as an integer. The last\n",
    "        element represents the diet of a patient. If a patient has a good diet\n",
    "        this string will be 'good'. All other values represent that the patient\n",
    "        has a poor diet.\n",
    "    Returns:\n",
    "        str: A string that has either the value 'more' or 'less'. No other return value\n",
    "        is valid.\n",
    "\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    if x[0] == 'yes':\n",
    "        if x[1] < 29.5:\n",
    "            return 'less'\n",
    "        else:\n",
    "            return 'more'\n",
    "        \n",
    "    else:\n",
    "        if x[2] == 'good':\n",
    "            return 'less'\n",
    "        else:\n",
    "            return 'more'\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9eae9d6986516961671f4a92c14ccf6",
     "grade": true,
     "grade_id": "cell-c31b80471db3132f",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision(('yes', 31, 'good')) --> more\n",
      "decision(('yes', 29, 'poor')) --> less\n"
     ]
    }
   ],
   "source": [
    "# Test decision function\n",
    "\n",
    "# Test expected 'more'\n",
    "x = (\"yes\", 31, \"good\")\n",
    "output = decision(x)\n",
    "print(f\"decision({x}) --> {output}\")\n",
    "t.assertIsInstance(output, str)\n",
    "t.assertEqual(output, \"more\")\n",
    "\n",
    "# Test expected 'less'\n",
    "x = (\"yes\", 29, \"poor\")\n",
    "output = decision(x)\n",
    "print(f\"decision({x}) --> {output}\")\n",
    "t.assertIsInstance(output, str)\n",
    "t.assertEqual(output, \"less\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a002cdeb30f449ded2d741a0cecaac82",
     "grade": true,
     "grade_id": "cell-a706e6de3303d3e7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7cc7299e6420360587d7e773a99bbd7f",
     "grade": false,
     "grade_id": "cell-f99e2c2efcd83d8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Reading a dataset from a text file (10 P)\n",
    "In the previous task we created a method to classify the risk of patients, by manualy setting rules defining for which inputs the user is in `more` or `less` risk regarding their health. In the next exercises we will approach the task differently. Our goal is to create a classification method based on data. In order to achieve this we need to also create functions that loads the existing data into the program so that we can use it. Furthermore, we can use the loaded data to apply on our decision tree implementation and check what its outputs are.\n",
    "\n",
    "The file `health-test.txt` contains several fictious records of personal data and habits. We split this task into two parts. In the first part, we assume that we have read a line from the file and can now process it. In the second function we load the file and process each line using the function we have defined for this purpose.\n",
    "\n",
    "* Read the file automatically using the methods introduced during the lecture.\n",
    "* Represent the dataset as a list of tuples. Make sure that the tuples have the same format as in the previous task, e.g. `('yes', 31, 'good')`.\n",
    "* Make sure that you close the file after you have opened it and read its content. If you use a `with` statement then you don't have to worry about closing the file.\n",
    "\n",
    "**Notes**: \n",
    "* Make sure when opening a file not to use an absolute path. An absolute path will\n",
    "work on your computer, but when your code is tested on the departments computers it will fail. Use relative paths when opening files\n",
    "* Values read from files are always strings.\n",
    "* Each line contains a newline `\\n` character at the end\n",
    "* If you are using Windows as your operating system, refrain from opening any text files using Notepad. It will remove any linebreaks `\\n`. You should inspect the files using the Jupyter text editor or any other modern text editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f784ce11aadd5b8ec7b64898160c1bc",
     "grade": false,
     "grade_id": "cell-c1a8bc4c0e4ccb26",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def parse_line_test(line):\n",
    "    \"\"\"\n",
    "    Takes a line from the file, including a newline, and parses it into a patient tuple\n",
    "\n",
    "    Args:\n",
    "        line: A line from the `health-test.txt` file\n",
    "    Returns:\n",
    "        tuple: A tuple representing a patient\n",
    "    \"\"\"\n",
    "    assert (\n",
    "        line[-1] == \"\\n\"\n",
    "    ), \"Did you change the contents of the line before calling this function?\"\n",
    "    # YOUR CODE HERE\n",
    "    details = line.strip().split(',')\n",
    "\n",
    "    details = [int(x) if x.isnumeric() else x for x in details]\n",
    "\n",
    "    return tuple(details)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2eac7abcbfcadd25ab7252247ffbc879",
     "grade": true,
     "grade_id": "cell-4e1f7ad1e66b3121",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('yes', 23, 'good')\n"
     ]
    }
   ],
   "source": [
    "x = \"yes,23,good\\n\"\n",
    "parsed_line = parse_line_test(x)\n",
    "smoker, age, diet = parsed_line\n",
    "print(parsed_line)\n",
    "t.assertIsInstance(parsed_line, tuple)\n",
    "t.assertEqual(len(parsed_line), 3)\n",
    "t.assertIsInstance(age, int)\n",
    "t.assertNotIn(\"\\n\", diet, \"Are you handling line breaks correctly?\")\n",
    "t.assertEqual(parsed_line[-1], \"good\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff88dfc864c57b2eb8238574d968d84e",
     "grade": true,
     "grade_id": "cell-0ed341eaf90d76a6",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6794e8729fe6211a2c3a61fb50c0c9cb",
     "grade": false,
     "grade_id": "cell-844c38f934d4a3ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gettest():\n",
    "    \"\"\"\n",
    "    Opens the `health-test.txt` file and parses it\n",
    "    into a list of patient tuples. You are encouraged to use\n",
    "    the `parse_line_test` function but it is not necessary to do so.\n",
    "\n",
    "    This functions assumes that the `health-test.txt` file is located in\n",
    "    the same directory as this notebook.\n",
    "\n",
    "    Returns:\n",
    "        A list of patient tuples as read from the file.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    list_of_patients = []\n",
    "\n",
    "    f = open(\"health-test.txt\", \"r\")\n",
    "    for x in f:\n",
    "        list_of_patients.append(parse_line_test(x))\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return list_of_patients\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3272a62886b113d328e28dede8f89973",
     "grade": true,
     "grade_id": "cell-ab1b01fcaac26cd5",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('yes', 21, 'poor'),\n",
      " ('no', 50, 'good'),\n",
      " ('no', 23, 'good'),\n",
      " ('yes', 45, 'poor'),\n",
      " ('yes', 51, 'good'),\n",
      " ('no', 60, 'good'),\n",
      " ('no', 15, 'poor'),\n",
      " ('no', 18, 'good')]\n"
     ]
    }
   ],
   "source": [
    "testset = gettest()\n",
    "pprint(testset)\n",
    "t.assertIsInstance(testset, list)\n",
    "t.assertEqual(len(testset), 8)\n",
    "t.assertIsInstance(testset[0], tuple)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69a5d31521d79fb22447e17337cc2aa8",
     "grade": true,
     "grade_id": "cell-42b0a5cad68fc15a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the decision tree to the dataset (15 P)\n",
    "\n",
    "* Apply the decision tree to all points in the dataset, and return the ratio of them that are classified as \"more\".\n",
    "* A ratio is a value in [0-1]. So if out of 50 data points 15 return `\"more\"` the value that should be returned is `0.3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f6cc89d98f440c1084f30e625ebcdab9",
     "grade": false,
     "grade_id": "cell-6703ef98e2b5c93b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_testset(dataset):\n",
    "    \"\"\"\n",
    "    Calculates the percentage of datapoints for which the\n",
    "    decision function evaluates to `more` for a given dataset\n",
    "\n",
    "    Args:\n",
    "        A list of patient tuples\n",
    "\n",
    "    Returns:\n",
    "        float: The percentage of data points which are evaluated to `'more'`\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    count = 0\n",
    "    for data in dataset:\n",
    "        if decision(data) == 'more':\n",
    "            count +=1\n",
    "    \n",
    "    return count/len(dataset)\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff3a9b739bac025fe84b8b2b782b3a1e",
     "grade": true,
     "grade_id": "cell-c13a0b23c9faba52",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio --> 0.375\n"
     ]
    }
   ],
   "source": [
    "ratio = evaluate_testset(gettest())\n",
    "print(f\"ratio --> {ratio}\")\n",
    "t.assertIsInstance(ratio, float)\n",
    "assert_percentage(ratio)\n",
    "t.assertTrue(0.3 < ratio < 0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning from examples (10 P)\n",
    "\n",
    "Suppose that instead of relying on a fixed decision tree, we would like to use a data-driven approach where data points are classified based on a set of training observations manually labeled by experts. Such labeled dataset is available in the file `health-train.txt`. The first three columns have the same meaning than for `health-test.txt`, and the last column corresponds to the labels.\n",
    "\n",
    "* Read the `health-train.txt` file and convert it into a list of pairs. The first element of each pair is a triplet of attributes (the patient tuple), and the second element is the label.\n",
    "* Similarlly to the previous exercise we split the task into two parts. The first involves processing each line individually. The second handles opening the file and processing all lines of the file\n",
    "\n",
    "**Note**: A triplet is a tuple that contains exactly three values, a pair is a tuple that contains exactly two values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "283d3e39ef1001f45703dcf587e01e1f",
     "grade": false,
     "grade_id": "cell-fc38ed11fee6fbeb",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def parse_line_train(line):\n",
    "    \"\"\"\n",
    "    This function works similarly to the `parse_line_test` function.\n",
    "    It parses a line of the `health-train.txt` file into a tuple that\n",
    "    contains a patient tuple and a label.\n",
    "\n",
    "    Args:\n",
    "        line: A line from the `health-train.txt`\n",
    "\n",
    "    Returns:\n",
    "        A tuple that contains a patient tuple and a label as a string\n",
    "    \"\"\"\n",
    "    assert line[-1] == \"\\n\"\n",
    "    # YOUR CODE HERE\n",
    "    details = line.strip().split(',')\n",
    "\n",
    "    details = [int(x) if x.isnumeric() else x for x in details]\n",
    "\n",
    "    return (tuple(details[:3]),details[3])\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d853d0f3f340cb19738db737d391ec9",
     "grade": true,
     "grade_id": "cell-b97620858b167c0d",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('yes', 67, 'poor'), 'more')\n"
     ]
    }
   ],
   "source": [
    "x = \"yes,67,poor,more\\n\"\n",
    "parsed_line = parse_line_train(x)\n",
    "print(parsed_line)\n",
    "\n",
    "t.assertIsInstance(parsed_line, tuple)\n",
    "t.assertEqual(len(parsed_line), 2)\n",
    "\n",
    "data, label = parsed_line\n",
    "\n",
    "t.assertIsInstance(data, tuple)\n",
    "t.assertEqual(len(data), 3)\n",
    "t.assertEqual(data[1], 67)\n",
    "\n",
    "t.assertIsInstance(label, str)\n",
    "t.assertNotIn(\"\\n\", label, \"Are you handling line breaks correctly?\")\n",
    "t.assertEqual(label, \"more\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d360bdd66c4f65216fb37dc1c36f30a",
     "grade": true,
     "grade_id": "cell-ced9925599b5dd99",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "940b721a3ece1e438fb7c3db1a2e32c2",
     "grade": false,
     "grade_id": "cell-183f0bbeecd179c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gettrain():\n",
    "    \"\"\"\n",
    "    Opens the `health-train.txt` file and parses it into\n",
    "    a list of patient tuples accompanied by their respective label.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples comprised of a patient tuple and a label\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    list_of_patients = []\n",
    "\n",
    "    f = open(\"health-train.txt\", \"r\")\n",
    "    for x in f:\n",
    "        list_of_patients.append(parse_line_train(x))\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return list_of_patients\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00f87b6b544cb271be54229ddb60b58c",
     "grade": true,
     "grade_id": "cell-a3d593f232e0403a",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('yes', 54, 'good'), 'less'),\n",
      " (('no', 55, 'good'), 'less'),\n",
      " (('no', 26, 'good'), 'less'),\n",
      " (('yes', 40, 'good'), 'more'),\n",
      " (('yes', 25, 'poor'), 'less'),\n",
      " (('no', 13, 'poor'), 'more'),\n",
      " (('no', 15, 'good'), 'less'),\n",
      " (('no', 50, 'poor'), 'more'),\n",
      " (('yes', 33, 'good'), 'more'),\n",
      " (('no', 35, 'good'), 'less'),\n",
      " (('no', 41, 'good'), 'less'),\n",
      " (('yes', 30, 'poor'), 'more'),\n",
      " (('no', 39, 'poor'), 'more'),\n",
      " (('no', 20, 'good'), 'less'),\n",
      " (('yes', 18, 'poor'), 'less'),\n",
      " (('yes', 55, 'good'), 'more')]\n"
     ]
    }
   ],
   "source": [
    "trainset = gettrain()\n",
    "pprint(trainset)\n",
    "t.assertIsInstance(trainset, list)\n",
    "t.assertEqual(len(trainset), 16)\n",
    "first_datapoint = trainset[0]\n",
    "t.assertIsInstance(first_datapoint, tuple)\n",
    "t.assertIsInstance(first_datapoint[0], tuple)\n",
    "t.assertIsInstance(first_datapoint[1], str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1745c8c6c934e4d3fb0ac74538015ad",
     "grade": true,
     "grade_id": "cell-7ab8ef2c931d69c1",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75338614be4f923d4472fb72227c5e05",
     "grade": false,
     "grade_id": "cell-1d2f1c357ea446c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Nearest neighbor classifier (25 P)\n",
    "\n",
    "We consider the nearest neighbor algorithm that classifies test points following the label of the nearest neighbor in the training data. You can read more about Nearest neighbor classifiers [here](http://www.robots.ox.ac.uk/~dclaus/digits/neighbour.htm). For this, we need to define a distance function between data points. We define it to be\n",
    "\n",
    "`distance(a, b) = (a[0] != b[0]) + ((a[1] - b[1]) / 50.0) ** 2 + (a[2] != b[2])`\n",
    "\n",
    "where `a` and `b` are two tuples representing two patients.\n",
    "\n",
    "* Implement the distance function.\n",
    "* Implement the function that retrieves for a test point the nearest neighbor in the training set, and classifies the test point accordingly (i.e. returns the label of the nearest data point).\n",
    "\n",
    "**Hint**: You can use the special `infinity` floating point value with `float('inf')`\n",
    "\n",
    "***Keep in mind that `bool`s in Python are also `int`s. `True` is the same as `1` and `False` is the same as `0`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9be277b87be909ce3fddbef8db363b5d",
     "grade": false,
     "grade_id": "cell-671ea24ec8a11241",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def distance(a, b):\n",
    "    \"\"\"\n",
    "    Calculates the distance between two data points (patient tuples)\n",
    "    Args:\n",
    "        a, b: Two patient tuples for which we want to calculate the distance\n",
    "    Returns:\n",
    "        float: The distance between a, b according to the above formula\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return (a[0] != b[0]) + ((a[1] - b[1]) / 50.0) ** 2 + (a[2] != b[2])\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7bd46b9f7ea55bdf131cdf91a1240e0",
     "grade": true,
     "grade_id": "cell-5929fce6ffc8ca0f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance(('yes', 34, 'poor'), ('yes', 51, 'good')) --> 1.1156\n"
     ]
    }
   ],
   "source": [
    "# Test distance\n",
    "x1 = (\"yes\", 34, \"poor\")\n",
    "x2 = (\"yes\", 51, \"good\")\n",
    "dist = distance(x1, x2)\n",
    "print(f\"distance({x1}, {x2}) --> {dist}\")\n",
    "expected_dist = 1.1156\n",
    "t.assertAlmostEqual(dist, expected_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3866d76d49cb35ab5cc87229ecf5d50",
     "grade": true,
     "grade_id": "cell-8dc0c32bc78d1e62",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b698fe93eba776ccdd59c4fa09a5fbea",
     "grade": false,
     "grade_id": "cell-e2ffaa5484ac1886",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def neighbor(x, trainset):\n",
    "    \"\"\"\n",
    "    Returns the label of the nearest data point in trainset to x.\n",
    "    If x is `('no', 30, 'good')` and the nearest data point in trainset\n",
    "    is `('no', 31, 'good')` with label `'less'` then `'less'` will be returned.\n",
    "    In case two elements have the exact same distance, element that first occurs\n",
    "    in the dataset is picked (the element with the smallest index).\n",
    "\n",
    "    Args:\n",
    "        x: The data point for which we want to find the nearest neighbor\n",
    "        trainset: A list of tuples with patient tuples and a label\n",
    "\n",
    "    Returns:\n",
    "        str: The label of the nearest data point in the trainset.\n",
    "        Can only be 'more' or 'less'\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    distances = [distance(x,a[0]) for a in trainset]\n",
    "\n",
    "    print(distances.index(min(distances)))\n",
    "\n",
    "    return trainset[distances.index(min(distances))][1]\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bffb2cd902697f310fa963e7ce38b603",
     "grade": true,
     "grade_id": "cell-a36122337853f195",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "prediction --> more\n"
     ]
    }
   ],
   "source": [
    "# Test neighbor\n",
    "x = (\"yes\", 31, \"good\")\n",
    "prediction = neighbor(x, gettrain())\n",
    "print(f\"prediction --> {prediction}\")\n",
    "expected = \"more\"\n",
    "t.assertEqual(prediction, expected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39d16b55bb994bf1f1b355e07a0040b0",
     "grade": true,
     "grade_id": "cell-cbf6ddfbfaab7875",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we want to compare the decision tree we have implemented with the nearest neighbor method. Apply both the decision tree and nearest neighbor classifiers on the test set, and return the list of data point(s) for which the two classifiers disagree, and with which probability it happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d85476e54e4e5e2d320a2c11be8e609f",
     "grade": false,
     "grade_id": "cell-8dbf7da153f3d797",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def compare_classifiers(trainset, testset):\n",
    "    \"\"\"\n",
    "    This function compares the two classification methods (decision tree, nearest neighbor)\n",
    "    by finding all the datapoints for which the methods disagree. It returns\n",
    "    a list of the test datapoints for which the two methods do not return\n",
    "    the same label as well as the ratio of those datapoints compared to the whole\n",
    "    test set.\n",
    "\n",
    "    Args:\n",
    "        trainset: The training set used by the nearest neighbour classfier.\n",
    "        testset: Contains the elements which will be used to compare the decision tree\n",
    "        and nearest neighbor classification methods.\n",
    "\n",
    "    Returns:\n",
    "        A list containing all the data points which yield different results for the two\n",
    "        classification methods. The ratio of datapoints for which the two methods\n",
    "        disagree.\n",
    "\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    dt_labels = [decision(x) for x in testset]\n",
    "    nn_labels = [neighbor(x,trainset) for x in testset]\n",
    "\n",
    "    difference = []\n",
    "\n",
    "    for i, item in enumerate(testset):\n",
    "        if(dt_labels[i] != nn_labels[i]):\n",
    "            difference.append(item)\n",
    "\n",
    "    return difference, len(difference)/len(testset)\n",
    "\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return disagree, percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "326ab2224269c5d8b6d0d61cd352e92b",
     "grade": true,
     "grade_id": "cell-3b55f7e89ad4dfeb",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "1\n",
      "2\n",
      "11\n",
      "0\n",
      "1\n",
      "5\n",
      "13\n",
      "ratio = 0.125\n"
     ]
    }
   ],
   "source": [
    "# Test compare_classifiers\n",
    "disagree, ratio = compare_classifiers(gettrain(), gettest())\n",
    "print(f\"ratio = {ratio}\")\n",
    "t.assertIsInstance(disagree, list)\n",
    "t.assertIsInstance(ratio, float)\n",
    "t.assertIsInstance(disagree[0], tuple)\n",
    "t.assertEqual(len(disagree[0]), 3)\n",
    "assert_percentage(ratio)\n",
    "t.assertTrue(0.1 < ratio < 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem of simple nearest neighbors is that one needs to compare the point to predict to all data points in the training set. This can be slow for datasets of thousands of points or more. Alternatively, some classifiers train a model first, and then use it to classify the data.\n",
    "\n",
    "## Nearest mean classifier (25 P)\n",
    "\n",
    "We consider one such trainable model, which operates in two steps:\n",
    "\n",
    "1. Compute the average point for each class\n",
    "2. Classify new points to be of the class whose average point is nearest to the point to predict.\n",
    "\n",
    "For this classifier, we convert the attributes smoker and diet to real values (for smoker: `1.0` if 'yes' otherwise `0.0`, and for diet: `0.0` if 'good' otherwise `1.0`), and use the modified distance function:\n",
    "\n",
    "`distance(a,b) = (a[0] - b[0]) ** 2 + ((a[1] - b[1]) / 50.0) ** 2 + (a[2] - b[2]) ** 2`\n",
    "\n",
    "Age will also from now on be represented as a `float`. The new data points will be referred to as numerical patient tuples. \n",
    "\n",
    "We adopt an object-oriented approach for building this classifier.\n",
    "\n",
    "* Implement the `gettrain_num` function that will load the training dataset from the `health-train.txt` file and parse each line to a numerical patient tuple with its label. You can still follow the same structure that we used before (i.e. using a `parse_line_...` function), however, it is not required for this exercise. Only the `gettrain_num` function will be tested.\n",
    "\n",
    "\n",
    "* Implement the new distance function.\n",
    "\n",
    "\n",
    "* Implement the methods `train` and `predict` of the class `NearestMeanClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40f0b7c3a9389a24608a5893f9d7fe78",
     "grade": false,
     "grade_id": "cell-efadd1b300bd22ec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def parse_line_train_num(\n",
    "    line,\n",
    "):\n",
    "    \"\"\"\n",
    "    Takes a line from the file `health-train.txt`, including a newline,\n",
    "    and parses it into a numerical patient tuple.\n",
    "\n",
    "    Args:\n",
    "        line: A line from the `health-test.txt` file\n",
    "    Returns:\n",
    "        A numerical patient tuple and its label\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Replace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "\n",
    "\n",
    "def gettrain_num():\n",
    "    \"\"\"\n",
    "    Parses the `health-train.txt` file into numerical patient tuples.\n",
    "\n",
    "    Returns:\n",
    "        A list of tuples containing numerical patient tuples and their labels\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Replace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e258d862a418a7d3606d5cdb3742f89",
     "grade": true,
     "grade_id": "cell-b8a19b27d4c7de88",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test gettrain_num\n",
    "trainset_num = gettrain_num()\n",
    "t.assertIsInstance(trainset_num, list)\n",
    "first_datapoint = trainset_num[0]\n",
    "print(f\"first_datapoint --> {first_datapoint}\")\n",
    "t.assertIsInstance(first_datapoint[0], tuple)\n",
    "t.assertIsInstance(first_datapoint[0][0], float)\n",
    "t.assertIsInstance(first_datapoint[0][1], float)\n",
    "t.assertIsInstance(first_datapoint[0][2], float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "90ffe9aae095119e420e54e50c3c355d",
     "grade": true,
     "grade_id": "cell-789233fd9f800e77",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a8bc6198dbfaad1abc3023297db9ef7",
     "grade": false,
     "grade_id": "cell-d35765538d512a1a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def distance_num(a, b):\n",
    "    \"\"\"\n",
    "    Calculates the distance between two numerical patient tuples.\n",
    "    Args:\n",
    "        a, b: Two numerical patient tuples for which we want to calculate the distance.\n",
    "    Returns:\n",
    "        float: The distance between a, b.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Replace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bfcc2da8bd0d4c591d5745940a893e19",
     "grade": true,
     "grade_id": "cell-de4d8b77145f3bff",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x1 = (1.0, 23.0, 0.0)\n",
    "x2 = (0.0, 41.0, 1.0)\n",
    "dist = distance_num(x1, x2)\n",
    "print(f\"dist --> {dist}\")\n",
    "t.assertIsInstance(dist, float)\n",
    "t.assertTrue(2.12 < dist < 2.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2b22e3ca4e043abde7cba27758fa484",
     "grade": true,
     "grade_id": "cell-28628e7373da18f2",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. DO NOT remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eec586419a2a86d014cf45ecdebaa42d",
     "grade": false,
     "grade_id": "cell-e0b339bfd0fcc16c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class NearestMeanClassifier:\n",
    "    \"\"\"\n",
    "    Represents a NearestMeanClassifier.\n",
    "\n",
    "    When an instance is trained a dataset is provided and the mean for each class is calculated.\n",
    "    During prediction the instance compares the datapoint to each class mean (not all datapoints)\n",
    "    and returns the label of the class mean to which the datapoint is closest to.\n",
    "\n",
    "    Instance Attributes:\n",
    "        more: A tuple representing the mean of\n",
    "        every 'more' data-point in the dataset\n",
    "        less: A tuple representing the mean of\n",
    "        every 'less' data-point in the dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.more = None\n",
    "        self.less = None\n",
    "\n",
    "    def train(self, dataset):\n",
    "        \"\"\"\n",
    "        Calculates the class means for a given dataset and stores\n",
    "        them in instance attributes more, less.\n",
    "\n",
    "        The mean of the more class is a tuple containing three elements.\n",
    "        Each element of the mean tuple contains the mean of all the elements\n",
    "        in the training set that are labeled `more` for each corresponding index.\n",
    "        This means that the mean tuple contains the mean smoker, age and health\n",
    "        values.\n",
    "        The same is true of the less mean tuple, but for all the elements\n",
    "        labeled `less`.\n",
    "\n",
    "        This function is does not return anything useful, but it has the side\n",
    "        effect of setting the more and less instance variables.\n",
    "\n",
    "        Args:\n",
    "            dataset: A list of tuples each of them containing a numerical patient tuple\n",
    "            and its label\n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError(\"Replace this line with your code\")\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Returns a prediction/label for numeric patient tuple x.\n",
    "        The classifier compares the given data point to the mean\n",
    "        class tuples of each class and returns the label of the\n",
    "        class to which x is the closest to (according to our\n",
    "        distance function).\n",
    "\n",
    "        Args:\n",
    "            x: A numerical patient tuplefor which we want a prediction\n",
    "        Returns:\n",
    "            str: The predicted label.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError(\"Replace this line with your code\")\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "\n",
    "    def __repr__(self):\n",
    "        try:\n",
    "            more = tuple(round(m, 3) for m in self.more)\n",
    "            less = tuple(round(l, 3) for l in self.less)\n",
    "        except AttributeError:\n",
    "            more, less = None, None\n",
    "        return f\"{self.__class__.__name__}(more: {more}, less: {less})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instantiate the `NearestMeanClassifier`, train it on the training data, and return it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "469360bff51517186c8281d9f98afacf",
     "grade": false,
     "grade_id": "cell-5f7f00ee83c94703",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def build_and_train(trainset_num):\n",
    "    \"\"\"\n",
    "    Instantiates the `NearestMeanClassifier`, trains it on the\n",
    "    `trainset_num` dataset and returns it.\n",
    "\n",
    "    Args:\n",
    "        trainset_num: A list of numerical patient tuples with their respective labels\n",
    "\n",
    "    Returns:\n",
    "        NearestMeanClassifier: A NearestMeanClassifier trained on `trainset_num`\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Replace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2b4419f8346adc333e596f12739b635",
     "grade": true,
     "grade_id": "cell-415891bde4cbde19",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test build_and_train\n",
    "classifier = NearestMeanClassifier()\n",
    "classifier.train(trainset_num)\n",
    "t.assertIsInstance(classifier, NearestMeanClassifier)\n",
    "print(classifier)\n",
    "try:\n",
    "    classifier.more, classifier.less\n",
    "except AttributeError:\n",
    "    t.fail(\n",
    "        \"Did you train the classifier?\"\n",
    "        \" Did you store the mean vector for the 'more' class?\"\n",
    "        \" Did you store the mean vector for the 'less' class?\",\n",
    "    )\n",
    "\n",
    "t.assertIsInstance(classifier.more, tuple)\n",
    "t.assertIsInstance(classifier.less, tuple)\n",
    "\n",
    "t.assertEqual(round(classifier.more[1]), 37)\n",
    "t.assertEqual(round(classifier.less[1]), 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "537c8f2b10eeeb376715afb96f2a8e63",
     "grade": true,
     "grade_id": "cell-ca2d0921e96ede25",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is for grading. Do NOT remove it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the test dataset into memory as a list of numerical patient tuples\n",
    "* Predict the test data using the nearest mean classifier and return the index of all test examples for which all three classifiers (decision tree, nearest neighbor and nearest mean) agree.\n",
    "\n",
    "**Note**: Be careful that the `NearestMeanClassifier` expects the dataset in a different form, compared to the other two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc49c26a4aeabb8e4b7522ec937b80e8",
     "grade": false,
     "grade_id": "cell-f37f3035a32a8f85",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def gettest_num():\n",
    "    \"\"\"\n",
    "    Parses the `health-test.txt` file into numerical patient tuples.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing numerical patient tuples, loaded from `health-test.txt`\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Replace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c340b09ad8ffbd109d302c8e4f6234a2",
     "grade": true,
     "grade_id": "cell-f3656461c994dc3d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "testset_num = gettest_num()\n",
    "pprint(testset_num)\n",
    "t.assertIsInstance(testset_num, list)\n",
    "t.assertEqual(len(testset_num), 8)\n",
    "t.assertIsInstance(testset_num[0], tuple)\n",
    "t.assertEqual(len(testset_num[0]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ee371ca7193ff2a940dd707ab2e3948",
     "grade": false,
     "grade_id": "cell-008fcc0d21f07c3a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_test():\n",
    "    \"\"\"\n",
    "    Classifies the test set using all the methods that were developed in this exercise sheet,\n",
    "    namely `decision`, `neighbor` and `NearestMeanClassifier`.\n",
    "\n",
    "    This functions loads all the needed data by calling the corresponding functions.\n",
    "    (gettrain, gettest, gettrain_num, gettest_num)\n",
    "\n",
    "    Returns:\n",
    "        A list of the indices of all the datapoints for which all three classfiers have\n",
    "        the same output.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError(\"Replace this line with your code\")\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return agreed_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3f238f2355ce3b4fb7152810da816a1",
     "grade": true,
     "grade_id": "cell-853c957eaaf81c28",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "same_predictions = predict_test()\n",
    "pprint(same_predictions)\n",
    "t.assertIsInstance(same_predictions, list)\n",
    "t.assertEqual(len(same_predictions), 6)\n",
    "t.assertIsInstance(same_predictions[0], int)\n",
    "t.assertEqual(same_predictions[-2:], [6, 7])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "44c5ad24b38bf5635972e4fed3ae8fab8ae159f27dbd9d55707f2021a5afe6c3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
